{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff3750a8-791b-4bd8-a887-2684fc4b3a43",
   "metadata": {},
   "source": [
    "# Software Engineering Study Assistant - RAG Pipeline\n",
    "\n",
    "This notebook implements a Retrieval-Augmented Generation (RAG) chatbot designed to help software engineering students with:\n",
    "- **Understanding complex topics** from lecture notes and textbooks\n",
    "- **Solving previous year exam questions** with detailed explanations\n",
    "- **Getting contextual answers** from course materials and PDFs\n",
    "- **Study assistance** with proper references to source materials\n",
    "\n",
    "**Technology Stack:**\n",
    "- **PyMuPDF** for PDF lecture notes extraction\n",
    "- **LangChain's RecursiveCharacterTextSplitter** for intelligent text chunking\n",
    "- **Sentence Transformers** (all-MiniLM-L6-v2) for semantic embeddings\n",
    "- **ChromaDB** for fast similarity search across study materials\n",
    "- **LangChain's retriever** for relevant content retrieval\n",
    "- **Gemini Pro** for generating comprehensive answers with context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac40ff48-d0a0-4c31-8b82-3bc1551f7801",
   "metadata": {},
   "source": [
    "## Study Assistant Pipeline Flow\n",
    "\n",
    "```\n",
    "Lecture Notes PDFs → PyMuPDF → Text Extraction → RecursiveCharacterTextSplitter → Knowledge Chunks\n",
    "                                                           ↓\n",
    "                                              Sentence Transformers → Semantic Embeddings → ChromaDB Knowledge Base\n",
    "                                                           ↓\n",
    "Student Question/Problem → Query Embedding → LangChain Retriever → Relevant Study Materials\n",
    "                                                           ↓\n",
    "                        Gemini Pro ← Context + Question → Detailed Answer with References\n",
    "```\n",
    "\n",
    "**Use Cases:**\n",
    "- \"Explain object-oriented programming concepts\"\n",
    "- \"How do I solve this data structures problem?\"\n",
    "- \"What are the key points about software testing methodologies?\"\n",
    "- \"Help me understand this previous year question on algorithms\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fa5e3c-5486-4fc6-b316-958d3bc895ac",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Install all required packages using the requirements.txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2257b5fe-79df-4791-9c18-3ab2222d7330",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF>=1.23.0 in ./env/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (1.26.3)\n",
      "Requirement already satisfied: langchain-community in ./env/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (0.3.27)\n",
      "Requirement already satisfied: langchain>=0.1.0 in ./env/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (0.3.27)\n",
      "Requirement already satisfied: langchain-google-genai>=1.0.0 in ./env/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (2.0.10)\n",
      "Requirement already satisfied: sentence-transformers>=2.2.0 in ./env/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (5.1.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./env/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (2.8.0)\n",
      "Requirement already satisfied: transformers>=4.30.0 in ./env/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (4.55.0)\n",
      "Requirement already satisfied: chromadb>=0.4.0 in ./env/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (1.0.16)\n",
      "Requirement already satisfied: google-generativeai>=0.3.0 in ./env/lib/python3.12/site-packages (from -r requirements.txt (line 21)) (0.8.5)\n",
      "Requirement already satisfied: numpy>=1.24.0 in ./env/lib/python3.12/site-packages (from -r requirements.txt (line 24)) (2.3.2)\n",
      "Requirement already satisfied: pandas>=2.0.0 in ./env/lib/python3.12/site-packages (from -r requirements.txt (line 25)) (2.3.1)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./env/lib/python3.12/site-packages (from -r requirements.txt (line 26)) (4.67.1)\n",
      "Requirement already satisfied: jupyter>=1.0.0 in ./env/lib/python3.12/site-packages (from -r requirements.txt (line 29)) (1.1.1)\n",
      "Requirement already satisfied: ipykernel>=6.25.0 in ./env/lib/python3.12/site-packages (from -r requirements.txt (line 30)) (6.30.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in ./env/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 8)) (0.3.74)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./env/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 8)) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in ./env/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 8)) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./env/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 8)) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./env/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 8)) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./env/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 8)) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./env/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 8)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./env/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 8)) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in ./env/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 8)) (0.4.14)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./env/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 8)) (0.4.1)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./env/lib/python3.12/site-packages (from langchain>=0.1.0->-r requirements.txt (line 9)) (0.3.9)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./env/lib/python3.12/site-packages (from langchain>=0.1.0->-r requirements.txt (line 9)) (2.11.7)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./env/lib/python3.12/site-packages (from langchain-google-genai>=1.0.0->-r requirements.txt (line 10)) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.12/site-packages (from sentence-transformers>=2.2.0->-r requirements.txt (line 13)) (1.7.1)\n",
      "Requirement already satisfied: scipy in ./env/lib/python3.12/site-packages (from sentence-transformers>=2.2.0->-r requirements.txt (line 13)) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./env/lib/python3.12/site-packages (from sentence-transformers>=2.2.0->-r requirements.txt (line 13)) (0.34.4)\n",
      "Requirement already satisfied: Pillow in ./env/lib/python3.12/site-packages (from sentence-transformers>=2.2.0->-r requirements.txt (line 13)) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./env/lib/python3.12/site-packages (from sentence-transformers>=2.2.0->-r requirements.txt (line 13)) (4.14.1)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (3.18.0)\n",
      "Requirement already satisfied: setuptools in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (2025.7.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 14)) (3.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.12/site-packages (from transformers>=4.30.0->-r requirements.txt (line 15)) (25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./env/lib/python3.12/site-packages (from transformers>=4.30.0->-r requirements.txt (line 15)) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./env/lib/python3.12/site-packages (from transformers>=4.30.0->-r requirements.txt (line 15)) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./env/lib/python3.12/site-packages (from transformers>=4.30.0->-r requirements.txt (line 15)) (0.6.2)\n",
      "Requirement already satisfied: build>=1.0.3 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in ./env/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.0->-r requirements.txt (line 18)) (0.35.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (1.36.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (33.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (3.11.2)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (14.1.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in ./env/lib/python3.12/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 18)) (4.25.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in ./env/lib/python3.12/site-packages (from google-generativeai>=0.3.0->-r requirements.txt (line 21)) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in ./env/lib/python3.12/site-packages (from google-generativeai>=0.3.0->-r requirements.txt (line 21)) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in ./env/lib/python3.12/site-packages (from google-generativeai>=0.3.0->-r requirements.txt (line 21)) (2.178.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in ./env/lib/python3.12/site-packages (from google-generativeai>=0.3.0->-r requirements.txt (line 21)) (2.40.3)\n",
      "Requirement already satisfied: protobuf in ./env/lib/python3.12/site-packages (from google-generativeai>=0.3.0->-r requirements.txt (line 21)) (5.29.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in ./env/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai>=0.3.0->-r requirements.txt (line 21)) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.12/site-packages (from pandas>=2.0.0->-r requirements.txt (line 25)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.12/site-packages (from pandas>=2.0.0->-r requirements.txt (line 25)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./env/lib/python3.12/site-packages (from pandas>=2.0.0->-r requirements.txt (line 25)) (2025.2)\n",
      "Requirement already satisfied: notebook in ./env/lib/python3.12/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 29)) (7.4.5)\n",
      "Requirement already satisfied: jupyter-console in ./env/lib/python3.12/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 29)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in ./env/lib/python3.12/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 29)) (7.16.6)\n",
      "Requirement already satisfied: ipywidgets in ./env/lib/python3.12/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 29)) (8.1.7)\n",
      "Requirement already satisfied: jupyterlab in ./env/lib/python3.12/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 29)) (4.4.5)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./env/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 30)) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./env/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 30)) (1.8.16)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./env/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 30)) (9.4.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in ./env/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 30)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./env/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 30)) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./env/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 30)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in ./env/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 30)) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in ./env/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 30)) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=25 in ./env/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 30)) (27.0.1)\n",
      "Requirement already satisfied: tornado>=6.2 in ./env/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 30)) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./env/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 30)) (5.14.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8)) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8)) (1.20.1)\n",
      "Requirement already satisfied: pyproject_hooks in ./env/lib/python3.12/site-packages (from build>=1.0.3->chromadb>=0.4.0->-r requirements.txt (line 18)) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./env/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 8)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./env/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 8)) (0.9.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./env/lib/python3.12/site-packages (from google-api-core->google-generativeai>=0.3.0->-r requirements.txt (line 21)) (1.70.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./env/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai>=0.3.0->-r requirements.txt (line 21)) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./env/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai>=0.3.0->-r requirements.txt (line 21)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./env/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai>=0.3.0->-r requirements.txt (line 21)) (4.9.1)\n",
      "Requirement already satisfied: anyio in ./env/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (4.10.0)\n",
      "Requirement already satisfied: certifi in ./env/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in ./env/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (1.0.9)\n",
      "Requirement already satisfied: idna in ./env/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./env/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./env/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=2.2.0->-r requirements.txt (line 13)) (1.1.7)\n",
      "Requirement already satisfied: decorator in ./env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 30)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 30)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 30)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 30)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 30)) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 30)) (2.19.2)\n",
      "Requirement already satisfied: stack_data in ./env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 30)) (0.6.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./env/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./env/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./env/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (0.27.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./env/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=6.25.0->-r requirements.txt (line 30)) (4.3.8)\n",
      "Requirement already satisfied: six>=1.9.0 in ./env/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (1.17.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./env/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./env/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in ./env/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (3.3.1)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in ./env/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (2.5.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in ./env/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (0.10)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community->-r requirements.txt (line 8)) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./env/lib/python3.12/site-packages (from langsmith>=0.1.125->langchain-community->-r requirements.txt (line 8)) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./env/lib/python3.12/site-packages (from langsmith>=0.1.125->langchain-community->-r requirements.txt (line 8)) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in ./env/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb>=0.4.0->-r requirements.txt (line 18)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./env/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb>=0.4.0->-r requirements.txt (line 18)) (25.2.10)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in ./env/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in ./env/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.36.0 in ./env/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in ./env/lib/python3.12/site-packages (from opentelemetry-sdk>=1.2.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (0.57b0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./env/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in ./env/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.0->-r requirements.txt (line 9)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.0->-r requirements.txt (line 9)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.0->-r requirements.txt (line 9)) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./env/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->-r requirements.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./env/lib/python3.12/site-packages (from requests<3,>=2->langchain-community->-r requirements.txt (line 8)) (3.4.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./env/lib/python3.12/site-packages (from rich>=10.11.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (4.0.0)\n",
      "Requirement already satisfied: greenlet>=1 in ./env/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain-community->-r requirements.txt (line 8)) (3.2.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./env/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 14)) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in ./env/lib/python3.12/site-packages (from typer>=0.9.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./env/lib/python3.12/site-packages (from typer>=0.9.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./env/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.0->-r requirements.txt (line 18)) (0.6.4)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in ./env/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.0->-r requirements.txt (line 18)) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./env/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.0->-r requirements.txt (line 18)) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in ./env/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.0->-r requirements.txt (line 18)) (15.0.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in ./env/lib/python3.12/site-packages (from google-api-python-client->google-generativeai>=0.3.0->-r requirements.txt (line 21)) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in ./env/lib/python3.12/site-packages (from google-api-python-client->google-generativeai>=0.3.0->-r requirements.txt (line 21)) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in ./env/lib/python3.12/site-packages (from google-api-python-client->google-generativeai>=0.3.0->-r requirements.txt (line 21)) (4.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./env/lib/python3.12/site-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 29)) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./env/lib/python3.12/site-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 29)) (3.0.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 14)) (3.0.2)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in ./env/lib/python3.12/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (2.0.5)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in ./env/lib/python3.12/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (2.2.6)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in ./env/lib/python3.12/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (2.16.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in ./env/lib/python3.12/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in ./env/lib/python3.12/site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (0.2.4)\n",
      "Requirement already satisfied: beautifulsoup4 in ./env/lib/python3.12/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 29)) (4.13.4)\n",
      "Requirement already satisfied: bleach!=5.0.0 in ./env/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 29)) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in ./env/lib/python3.12/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 29)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./env/lib/python3.12/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 29)) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in ./env/lib/python3.12/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 29)) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in ./env/lib/python3.12/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 29)) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in ./env/lib/python3.12/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 29)) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./env/lib/python3.12/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 29)) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./env/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.2.0->-r requirements.txt (line 13)) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./env/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.2.0->-r requirements.txt (line 13)) (3.6.0)\n",
      "Requirement already satisfied: webencodings in ./env/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 29)) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in ./env/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 29)) (1.4.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in ./env/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.3.0->-r requirements.txt (line 21)) (1.71.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in ./env/lib/python3.12/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai>=0.3.0->-r requirements.txt (line 21)) (3.2.3)\n",
      "Requirement already satisfied: zipp>=3.20 in ./env/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (3.23.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./env/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 30)) (0.8.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./env/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community->-r requirements.txt (line 8)) (3.0.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in ./env/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in ./env/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in ./env/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (0.5.3)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in ./env/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (0.22.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in ./env/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./env/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (0.18.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./env/lib/python3.12/site-packages (from anyio->httpx>=0.27.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (1.3.1)\n",
      "Requirement already satisfied: babel>=2.10 in ./env/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in ./env/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (0.12.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./env/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.4.0->-r requirements.txt (line 18)) (0.1.2)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./env/lib/python3.12/site-packages (from nbformat>=5.7->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 29)) (2.21.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./env/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 30)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./env/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 30)) (0.2.13)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./env/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai>=0.3.0->-r requirements.txt (line 21)) (0.6.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./env/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./env/lib/python3.12/site-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 29)) (2.7)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./env/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.4.0->-r requirements.txt (line 18)) (10.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./env/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 30)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./env/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 30)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./env/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 30)) (0.2.3)\n",
      "Requirement already satisfied: argon2-cffi-bindings in ./env/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (25.1.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in ./env/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (3.3.0)\n",
      "Requirement already satisfied: rfc3339-validator in ./env/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in ./env/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (0.1.1)\n",
      "Requirement already satisfied: fqdn in ./env/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in ./env/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (20.11.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in ./env/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (1.1.0)\n",
      "Requirement already satisfied: uri-template in ./env/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in ./env/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in ./env/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (1.17.1)\n",
      "Requirement already satisfied: pycparser in ./env/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (2.22)\n",
      "Requirement already satisfied: lark>=1.2.2 in ./env/lib/python3.12/site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (1.2.2)\n",
      "Requirement already satisfied: arrow>=0.15.0 in ./env/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in ./env/lib/python3.12/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 29)) (2.9.0.20250809)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for RAG pipeline using requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c15eba-f97e-4555-b3d8-5607ad5dbcb5",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a703d29-9cb8-4040-8296-d5d7fd86090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import io\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "import uuid\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0dde4d-af1a-4f7e-bb42-6435e1a1ac60",
   "metadata": {},
   "source": [
    "## Gemini API Key Setup\n",
    "\n",
    "Get your free Gemini API key from [Google AI Studio](https://makersuite.google.com/app/apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f6deb0-ff3c-4efa-a2c5-b2585902df7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini API key configured\n",
      "API key starts with: AIzaSyCA...\n"
     ]
    }
   ],
   "source": [
    "# Set your Gemini API key\n",
    "GEMINI_API_KEY = \"AIzaSyCATHVWy8gTDiLCZCMcJxmqDw-u33X9cFQ\"  # Replace with your actual API key\n",
    "\n",
    "# Verify API key is set\n",
    "if GEMINI_API_KEY == \"your-gemini-api-key-here\":\n",
    "    print(\"Please replace 'your-gemini-api-key-here' with your actual Gemini API key\")\n",
    "    print(\"Get your free API key from: https://makersuite.google.com/app/apikey\")\n",
    "else:\n",
    "    print(\"Gemini API key configured\")\n",
    "    print(f\"API key starts with: {GEMINI_API_KEY[:8]}...\")\n",
    "\n",
    "# Set environment variable for Google Generative AI\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GEMINI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1bf069-b68b-4778-9986-c735eadc6ba0",
   "metadata": {},
   "source": [
    "## PDF Text Extraction with PyMuPDF\n",
    "\n",
    "This section handles text-based PDFs using direct text extraction:\n",
    "\n",
    "- **Text-based PDFs**: Direct text extraction using PyMuPDF for PDFs created from digital documents (Word, LaTeX, Google Docs, etc.)\n",
    "\n",
    "**Supported PDF Types:**\n",
    "- Documents created from Word processors\n",
    "- LaTeX-generated PDFs  \n",
    "- Google Docs exports\n",
    "- Any PDF with embedded text data\n",
    "\n",
    "The pipeline uses PyMuPDF for fast and accurate text extraction from digital documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969fd99f-fd8c-48af-a86f-6d0681f972be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Text-based PDFs ===\n",
      "Processing: metrics3.pdf\n",
      "  → Using direct text extraction\n",
      "Extracted 17980 characters from metrics3.pdf\n",
      "Processing: Lecture#7.pdf\n",
      "  → Using direct text extraction\n",
      "Extracted 19743 characters from Lecture#7.pdf\n",
      "Processing: Sample.pdf\n",
      "  → Using direct text extraction\n",
      "Extracted 20737 characters from Sample.pdf\n",
      "Processing: GreedyAlgorithms.pdf\n",
      "  → Using direct text extraction\n",
      "Extracted 19614 characters from GreedyAlgorithms.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'if all_extracted_text:\\n    print(f\"\\n=== EXTRACTION SUMMARY ===\")\\n    print(f\"Total extracted content: {len(all_extracted_text)} characters\")\\n    print(f\"PDFs processed: {len([p for p in pdf_paths if os.path.exists(p)])}\")\\n    print(f\"First 500 characters:\\n{all_extracted_text[:500]}...\")\\nelse:\\n    print(\"\\nNo PDF files were processed.\")\\n    print(\"Please add your text-based PDFs to the pdf_paths list\")'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract text from text-based PDFs using PyMuPDF\n",
    "    Use this for PDFs created from digital documents (Word, LaTeX, Google Docs, etc.)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"Warning: PDF file not found: {pdf_path}\")\n",
    "        return \"\"\n",
    "    \n",
    "    print(f\"Processing: {os.path.basename(pdf_path)}\")\n",
    "    print(f\"  → Using direct text extraction\")\n",
    "    \n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        page_text = page.get_text()\n",
    "        \n",
    "        if page_text.strip():  # Only add non-empty pages\n",
    "            text += f\"\\n\\n--- Lecture Page {page_num + 1} ---\\n\\n\"\n",
    "            text += page_text\n",
    "    \n",
    "    doc.close()\n",
    "    return text\n",
    "\n",
    "# Add your text-based PDFs here (created from Word, LaTeX, Google Docs, etc.)\n",
    "pdf_paths = [\n",
    "    \"./assets/metrics3.pdf\", \n",
    "    \"./assets/Lecture#7.pdf\",\n",
    "    \"./assets/Sample.pdf\",\n",
    "    \"./assets/GreedyAlgorithms.pdf\"\n",
    "]\n",
    "\n",
    "extracted_texts = {}\n",
    "\n",
    "print(\"=== Processing Text-based PDFs ===\")\n",
    "for pdf_path in pdf_paths:\n",
    "    if os.path.exists(pdf_path):\n",
    "        text = extract_text_from_pdf(pdf_path)\n",
    "        extracted_texts[os.path.basename(pdf_path)] = text\n",
    "        print(f\"Extracted {len(text)} characters from {os.path.basename(pdf_path)}\")\n",
    "    else:\n",
    "        print(f\"PDF file not found: {pdf_path}\")\n",
    "\n",
    "\"\"\"if all_extracted_text:\n",
    "    print(f\"\\n=== EXTRACTION SUMMARY ===\")\n",
    "    print(f\"Total extracted content: {len(all_extracted_text)} characters\")\n",
    "    print(f\"PDFs processed: {len([p for p in pdf_paths if os.path.exists(p)])}\")\n",
    "    print(f\"First 500 characters:\\n{all_extracted_text[:500]}...\")\n",
    "else:\n",
    "    print(\"\\nNo PDF files were processed.\")\n",
    "    print(\"Please add your text-based PDFs to the pdf_paths list\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64396d45-24a6-4f74-bd6f-837192ce30aa",
   "metadata": {},
   "source": [
    "### Understanding Text-based PDF Processing\n",
    "\n",
    "**Text-based PDFs**: Created from digital documents (Word, LaTeX, Google Docs, etc.) - contain actual text data that can be directly extracted.\n",
    "\n",
    "**Processing Features:**\n",
    "- Fast direct text extraction using PyMuPDF\n",
    "- Maintains original text formatting and structure\n",
    "- Works with all standard PDF formats containing embedded text\n",
    "- Preserves page structure with clear page separators\n",
    "\n",
    "**Best Results With:**\n",
    "- Documents created from word processors (Word, Google Docs, etc.)\n",
    "- LaTeX-generated academic papers and textbooks\n",
    "- Exported PDFs from presentation software\n",
    "- Any PDF with selectable/copyable text\n",
    "\n",
    "**Note**: This pipeline is optimized for text-based PDFs. If you have scanned documents (images of text), you would need OCR functionality, which can be added later if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaee036-7fe3-428b-9eae-43b3295a9222",
   "metadata": {},
   "source": [
    "## Text Chunking with LangChain's RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35b93c7-bdef-4e5f-8712-e8f08fd5d6d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks with Unknown source: 0\n"
     ]
    }
   ],
   "source": [
    "def create_overlapping_chunks(text: str, chunk_size: int = 1000, chunk_overlap: int = 200) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Split lecture notes into overlapping chunks for better retrieval\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_text(text)\n",
    "    \n",
    "    documents = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        doc = Document(\n",
    "            page_content=chunk,\n",
    "            metadata={\n",
    "                \"chunk_id\": i,\n",
    "                \"source\": \"Unknown\",  # default, will be overwritten later\n",
    "                \"chunk_size\": len(chunk),\n",
    "                \"content_type\": \"lecture_notes\"\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "documents = []\n",
    "\n",
    "for source, text in extracted_texts.items():\n",
    "    docs = create_overlapping_chunks(text)\n",
    "    for doc in docs:\n",
    "        doc.metadata[\"source\"] = source\n",
    "    documents.extend(docs)\n",
    "\n",
    "unknown_sources = [doc for doc in documents if doc.metadata.get(\"source\") == \"Unknown\"]\n",
    "print(f\"Chunks with Unknown source: {len(unknown_sources)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570165e3-f318-4750-9b7c-dff533916910",
   "metadata": {},
   "source": [
    "## Initialize Sentence Transformers for Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e03069e3-86c4-41b0-b386-a42c1f63ab71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12642/263079578.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Transformers (all-MiniLM-L6-v2) model loaded\n",
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Initialize Sentence Transformers embeddings\n",
    "embedding_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "print(\"Sentence Transformers (all-MiniLM-L6-v2) model loaded\")\n",
    "print(f\"Embedding dimension: 384\")  # all-MiniLM-L6-v2 produces 384-dimensional embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3738d9-c27b-468a-873d-d1bd54c7d643",
   "metadata": {},
   "source": [
    "## Create ChromaDB Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "574200c9-7d97-480e-9fb0-692f629b337b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Software Engineering Knowledge Base created with 124 chunks\n",
      "Database persisted to: ./chroma_db\n",
      "Your study materials are now ready for questions!\n",
      "Loaded vectorstore document metadata samples:\n",
      "Document 1 metadata: {'chunk_id': 11, 'content_type': 'lecture_notes', 'chunk_size': 900, 'source': 'Lecture#7.pdf'}\n",
      "Content preview: Cost Estimation Process\n",
      "Errors\n",
      "Effort\n",
      "Development Time\n",
      "Size Table\n",
      "Lines of Code\n",
      "Number of Use Case\n",
      "Function Point\n",
      "Estimation Process\n",
      "Number of Personn...\n",
      "\n",
      "Document 2 metadata: {'chunk_size': 813, 'source': 'Lecture#7.pdf', 'chunk_id': 1, 'content_type': 'lecture_notes'}\n",
      "Content preview: --- Lecture Page 4 ---\n",
      "\n",
      "Properties of Valid Software Size Measurement\n",
      "●Three properties for any valid measure of software size:\n",
      "Nonnegativity: All sy...\n",
      "\n",
      "Document 3 metadata: {'source': 'GreedyAlgorithms.pdf', 'chunk_size': 868, 'chunk_id': 9, 'content_type': 'lecture_notes'}\n",
      "Content preview: --- Lecture Page 19 ---\n",
      "\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "0     1      2      3      4     5      6      7     8      9    10    11    12    13   14    15   16...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12642/4024082326.py:14: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "# Set up ChromaDB knowledge base for study materials\n",
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "# Create or load ChromaDB vector store for educational content\n",
    "if 'documents' in locals() and documents:\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embedding_model,\n",
    "        persist_directory=persist_directory,\n",
    "        collection_name=\"software_engineering_knowledge_base\"\n",
    "    )\n",
    "    \n",
    "    # Persist the database\n",
    "    vectorstore.persist()\n",
    "    \n",
    "    print(f\"Software Engineering Knowledge Base created with {len(documents)} chunks\")\n",
    "    print(f\"Database persisted to: {persist_directory}\")\n",
    "    print(\"Your study materials are now ready for questions!\")\n",
    "else:\n",
    "    print(\"No study materials available for knowledge base creation\")\n",
    "print(\"Loaded vectorstore document metadata samples:\")\n",
    "results = vectorstore.similarity_search(\"test\", k=3)  # just a quick search to get some docs\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"Document {i} metadata: {doc.metadata}\")\n",
    "    print(f\"Content preview: {doc.page_content[:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc589e7-190f-4625-bf6c-a048c8ae49e0",
   "metadata": {},
   "source": [
    "## Create LangChain Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "844c0f3d-79dc-4a00-890e-98029763e424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12642/312979970.py:17: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(test_query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study Materials Retriever created\n",
      "Search type: similarity\n",
      "Number of chunks retrieved per query: 5\n",
      "\n",
      "Test retrieval for 'What is Function point?':\n",
      "Retrieved 1 relevant study materials\n",
      "First retrieved content preview:\n",
      "--- Lecture Page 27 ---\n",
      "\n",
      "Function Points Calculation\n",
      "STEP 1: Measure size in terms of the amount of functionality in a system.\n",
      "Function points are computed by first calculating an unadjusted function\n",
      "...\n",
      "Source: Lecture#7.pdf\n"
     ]
    }
   ],
   "source": [
    "# Create a retriever for study materials\n",
    "if 'vectorstore' in locals():\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={\n",
    "            \"score_threshold\": 0.4, #cosine_distance = 1 — cosine_similarity\n",
    "            \"k\": 5\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"Study Materials Retriever created\")\n",
    "    print(\"Search type: similarity\")\n",
    "    print(\"Number of chunks retrieved per query: 5\")\n",
    "    \n",
    "    # Test the retriever with a typical student question\n",
    "    test_query = \"What is Function point?\"\n",
    "    retrieved_docs = retriever.get_relevant_documents(test_query)\n",
    "    print(f\"\\nTest retrieval for '{test_query}':\")\n",
    "    print(f\"Retrieved {len(retrieved_docs)} relevant study materials\")\n",
    "    if retrieved_docs:\n",
    "        print(f\"First retrieved content preview:\\n{retrieved_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Source: {retrieved_docs[0].metadata.get('source', 'Unknown')}\")\n",
    "else:\n",
    "    print(\"Knowledge base not available for retriever creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebd0a0f",
   "metadata": {},
   "source": [
    "## Initialize Gemini Pro with API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b93a2499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Pro LLM initialized with API key\n",
      "Model: gemini-1.5-flash\n",
      "Temperature: 0.3\n",
      "Max output tokens: 1024\n"
     ]
    }
   ],
   "source": [
    "# Initialize Gemini Pro LLM with API key\n",
    "try:\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        google_api_key=GEMINI_API_KEY,\n",
    "        temperature=0.3,\n",
    "        max_output_tokens=1024\n",
    "    )\n",
    "    \n",
    "    print(\"Gemini Pro LLM initialized with API key\")\n",
    "    print(f\"Model: gemini-1.5-flash\")\n",
    "    print(f\"Temperature: 0.3\")\n",
    "    print(f\"Max output tokens: 1024\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Gemini Pro: {e}\")\n",
    "    print(\"Please ensure you have:\")\n",
    "    print(\"1. Valid Gemini API key\")\n",
    "    print(\"2. Correct API key format\")\n",
    "    print(\"3. Get your key from: https://makersuite.google.com/app/apikey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a6cfa",
   "metadata": {},
   "source": [
    "## Create RAG Chain with Custom Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af54bcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Software Engineering Study Assistant created successfully\n",
      "Chain type: stuff (combines all retrieved study materials)\n",
      "Returns source documents: Yes\n",
      "Ready to help with your studies!\n"
     ]
    }
   ],
   "source": [
    "# Define a custom prompt template for educational assistance\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are an AI Study Assistant for Software Engineering students. Your role is to help students understand concepts, solve problems, and prepare for exams using their course materials.\n",
    "\n",
    "Instructions:\n",
    "- Provide clear, detailed explanations suitable for students\n",
    "- Include examples when helpful for understanding\n",
    "- Reference the source materials when possible\n",
    "- For previous year questions, provide step-by-step solutions\n",
    "- If you need to make assumptions, state them clearly\n",
    "- If the context doesn't contain enough information, say so and suggest what additional materials might help\n",
    "\n",
    "Context from Study Materials:\n",
    "{context}\n",
    "\n",
    "Student Question: {question}\n",
    "\n",
    "Study Assistant Response:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# Create the Study Assistant RAG chain\n",
    "if 'llm' in locals() and 'retriever' in locals():\n",
    "    rag_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": prompt_template}\n",
    "    )\n",
    "    \n",
    "    print(\"Software Engineering Study Assistant created successfully\")\n",
    "    print(\"Chain type: stuff (combines all retrieved study materials)\")\n",
    "    print(\"Returns source documents: Yes\")\n",
    "    print(\"Ready to help with your studies!\")\n",
    "else:\n",
    "    print(\"Cannot create Study Assistant - missing LLM or retriever\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4746e52",
   "metadata": {},
   "source": [
    "## Test the RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42d8e0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12642/2236134622.py:11: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = rag_chain({\"query\": question})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Question: What are function points?\n",
      "\n",
      "Study Assistant Answer:\n",
      "Function points are a unit of measurement used to estimate the size of a software system based on its functionality, rather than lines of code or other implementation-specific metrics.  This is a crucial difference because it allows for a more abstract and technology-independent assessment of project size.  As described on Lecture Page 27, the process begins by calculating an *unadjusted function point count (UFC)*.\n",
      "\n",
      "The UFC is determined by counting instances within five key categories:\n",
      "\n",
      "1. **External Inputs:** These are data items provided by the user that trigger specific actions within the system.  Think of them as distinct pieces of information the system receives from the user. Examples include file names entered by a user, menu selections, or parameters entered into a form.  It's important to note that it's the *distinct* data items that are counted, not individual fields within a form, for instance.  If a user input form has a name, address, and phone number, that would count as *one* external input.\n",
      "\n",
      "2. **External Outputs:** These are data items provided *to* the user by the system as a result of processing.  These are distinct outputs, not individual components of a larger output.  For example, a report generated by the system would count as one external output, even if the report contains multiple tables and charts.  Similarly, a single error message would count as one external output.\n",
      "\n",
      "3. **External Inquiries:** These are interactive inputs from the user that require an immediate response from the system.  Think of them as requests for information, where the user provides input and receives an immediate output.  A simple database query where the user inputs a search term and receives a list of results would be an example.\n",
      "\n",
      "4. **External Files:** These are machine-readable interfaces to other systems.  These represent data exchanged with external systems, such as databases or other applications.  Each distinct interface would be counted as one external file.\n",
      "\n",
      "5. **Internal Files:** These are logical master files within the system itself.  These are files that the system uses to store and manage its own data.  Each distinct logical file would be counted as one internal file.  Note that a single physical file might contain multiple logical files (e.g., a database table might represent multiple internal files if it stores distinct types of data).\n",
      "\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Let's say we're building a simple inventory management system.\n",
      "\n",
      "* **External Inputs:**  Adding a new item (1), updating an existing item (1), deleting an item (1)  = 3\n",
      "* **External Outputs:** Generating a low-stock report (1), displaying a list of all items (1) = 2\n",
      "* **External Inquiries:** Searching for an item by name (1) = 1\n",
      "* **External Files:**  Connection to a supplier database (1) = 1\n",
      "* **Internal Files:** Inventory data (1), supplier data (1) = 2\n",
      "\n",
      "In this simplified example, the UFC would be 3 + 2 + 1 + 1 + 2 = 9.  Note that this is just the *unadjusted* function point count.  Further adjustments are typically made based on factors like the complexity of the system and the experience of the development team to arrive at a final function point count.  These adjustments are not covered in the provided lecture excerpt.  To understand the complete function point calculation, including the adjustment factors, you would need to consult additional materials from your course.\n",
      "\n",
      "Source Materials Referenced (1)\n",
      "--------------------------------------------------\n",
      "\n",
      "Source 1: Lecture#7.pdf (Chunk 13)\n",
      "Content Preview: --- Lecture Page 27 ---\n",
      "\n",
      "Function Points Calculation\n",
      "STEP 1: Measure size in terms of the amount of functionality in a system.\n",
      "Function points are com...\n"
     ]
    }
   ],
   "source": [
    "def ask_study_question(question: str):\n",
    "    \"\"\"\n",
    "    Ask a study-related question using the RAG pipeline\n",
    "    \"\"\"\n",
    "    if 'rag_chain' not in locals() and 'rag_chain' not in globals():\n",
    "        print(\"Study Assistant not available\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Get response from RAG chain\n",
    "        result = rag_chain({\"query\": question})\n",
    "        \n",
    "        print(f\"Student Question: {question}\")\n",
    "        print(f\"\\nStudy Assistant Answer:\\n{result['result']}\")\n",
    "        \n",
    "        # Show source materials referenced\n",
    "        print(f\"\\nSource Materials Referenced ({len(result['source_documents'])})\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, doc in enumerate(result['source_documents'], 1):\n",
    "            source = doc.metadata.get('source', 'Unknown')\n",
    "            chunk_id = doc.metadata.get('chunk_id', 'N/A')\n",
    "            print(f\"\\nSource {i}: {source} (Chunk {chunk_id})\")\n",
    "            print(f\"Content Preview: {doc.page_content[:150]}...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during study query: {e}\")\n",
    "\n",
    "# Test the Study Assistant with a sample question\n",
    "if 'rag_chain' in locals():\n",
    "    # Test with a typical software engineering question\n",
    "    ask_study_question(\"What are function points?\")\n",
    "else:\n",
    "    print(\"Study Assistant not ready for testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae045830",
   "metadata": {},
   "source": [
    "## Interactive Q&A Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1e01279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Asking: What is the COCOMO model and how to estimate the cost of a software?\n",
      "============================================================\n",
      "Student Question: What is the COCOMO model and how to estimate the cost of a software?\n",
      "\n",
      "Study Assistant Answer:\n",
      "The COCOMO (Constructive Cost Model) is a family of regression models used for estimating the effort and time required to develop a software project.  It's not a single model, but rather a set of models with increasing complexity: Basic, Intermediate, and Detailed (or Advanced).  The choice of model depends on the level of accuracy needed and the amount of information available.\n",
      "\n",
      "Let's break down each model and how to use them for cost estimation:\n",
      "\n",
      "**1. Basic COCOMO:**\n",
      "\n",
      "This is the simplest model. It estimates effort based solely on the estimated size of the software (in thousands of lines of code, KLOC).  The formula is:\n",
      "\n",
      "*Effort = a * KLOC<sup>b</sup>*\n",
      "\n",
      "Where:\n",
      "\n",
      "* **Effort:**  The estimated effort in person-months.\n",
      "* **a and b:**  Coefficients that depend on the software development mode (Organic, Semi-detached, or Embedded).  These values are provided in your lecture notes (Page 47).\n",
      "* **KLOC:** The estimated number of thousands of lines of code.\n",
      "\n",
      "Once effort is calculated, duration and the number of people required are estimated using these formulas:\n",
      "\n",
      "* **Duration = c * Effort<sup>d</sup>**\n",
      "* **PersonRequired = Effort / Duration**\n",
      "\n",
      "Where:\n",
      "\n",
      "* **c and d:** Coefficients that also depend on the software development mode (Page 47).\n",
      "\n",
      "\n",
      "**Example (Basic COCOMO):**\n",
      "\n",
      "Let's say we're developing an Organic software project estimated at 10 KLOC. Using the values from Page 47:\n",
      "\n",
      "* a = 2.4\n",
      "* b = 1.05\n",
      "* c = 2.5\n",
      "* d = 0.38\n",
      "\n",
      "Effort = 2.4 * 10<sup>1.05</sup> ≈ 24.4 person-months\n",
      "\n",
      "Duration = 2.5 * 24.4<sup>0.38</sup> ≈ 7.4 months\n",
      "\n",
      "PersonRequired = 24.4 / 7.4 ≈ 3.3 people\n",
      "\n",
      "\n",
      "**2. Intermediate COCOMO:**\n",
      "\n",
      "This model extends the Basic COCOMO by incorporating a set of \"cost driver attributes\" that influence the development effort.  These attributes reflect factors like product complexity, required reliability, programmer experience, use of modern programming practices, and more.  The formula becomes:\n",
      "\n",
      "*Effort = a * KLOC<sup>b</sup> * EAF*\n",
      "\n",
      "Where:\n",
      "\n",
      "* **EAF:** Effort Adjustment Factor. This is calculated by multiplying together values representing the influence of each cost driver attribute.  An ideal project has an EAF of 1.  The specific values for each attribute are not provided in your materials, but would be found in a complete COCOMO II specification.\n",
      "\n",
      "Duration and PersonRequired are calculated the same way as in Basic COCOMO.\n",
      "\n",
      "\n",
      "**3. Detailed (Advanced) COCOMO:**\n",
      "\n",
      "This is the most complex model. It breaks down the software project into individual modules or subsystems, each with its own characteristics and development phase (analysis, design, coding, testing, etc.).  Each module is estimated separately using the Intermediate COCOMO model, and the total effort is the sum of the individual module efforts.  This allows for a more accurate estimation, especially for large and complex projects.  The example on Page 55 illustrates this approach by estimating the cost of different components (database, GUI, communication) of a Management Information System separately.\n",
      "\n",
      "\n",
      "**Addressing the Student Question:**\n",
      "\n",
      "To estimate the cost of software using COCOMO, you first need to determine which COCOMO model is appropriate.  Basic COCOMO is suitable for quick, rough estimates when only KLOC is known. Intermediate COCOMO provides more accuracy by considering various cost drivers. Detailed COCOMO offers the highest accuracy but requires a detailed breakdown of the project into modules and phases.  After selecting the appropriate model, you apply the relevant formulas, using the appropriate coefficients and considering the EAF (for Intermediate and Detailed COCOMO).  Remember that you need additional information (specifically the cost driver attributes and their values) to use the Intermediate and Detailed COCOMO models effectively.  This information is typically found in a complete COCOMO II reference guide.  The provided lecture notes only give a high-level overview.\n",
      "\n",
      "Source Materials Referenced (5)\n",
      "--------------------------------------------------\n",
      "\n",
      "Source 1: Lecture#7.pdf (Chunk 23)\n",
      "Content Preview: --- Lecture Page 49 ---\n",
      "\n",
      "Intermediate COCOMO Model\n",
      "• Intermediate COCOMO model is an extension of the Basic COCOMO \n",
      "model which includes a set of cost...\n",
      "\n",
      "Source 2: Lecture#7.pdf (Chunk 26)\n",
      "Content Preview: --- Lecture Page 54 ---\n",
      "\n",
      "Detailed/Advanced COCOMO Model\n",
      "• The model accounts for the influence of the \n",
      "individual development phase (analysis, \n",
      "design...\n",
      "\n",
      "Source 3: Lecture#7.pdf (Chunk 27)\n",
      "Content Preview: --- Lecture Page 55 ---\n",
      "\n",
      "Detailed/Advanced COCOMO Model\n",
      "• In the Detailed COCOMO Model, the cost of each subsystem is estimated \n",
      "separately. This appr...\n",
      "\n",
      "Source 4: Sample.pdf (Chunk 33)\n",
      "Content Preview: --- Lecture Page 17 ---\n",
      "\n",
      " \n",
      "To calculate the efficiency of the project, we use the following formula: \n",
      " \n",
      "Where: \n",
      "●​ Actual KLOC = 3.011 KLOC (the real ...\n",
      "\n",
      "Source 5: Lecture#7.pdf (Chunk 21)\n",
      "Content Preview: --- Lecture Page 46 ---\n",
      "\n",
      "Basic COCOMO Model\n",
      "• The first level, Basic COCOMO can be used for quick and slightly\n",
      "rough calculations of Software Costs.\n",
      "•...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ask your own study question here\n",
    "your_question = \"What is the COCOMO model and how to estimate the cost of a software?\"  # Modify this\n",
    "\n",
    "if 'rag_chain' in locals():\n",
    "    print(f\"\\nAsking: {your_question}\")\n",
    "    print(\"=\" * 60)\n",
    "    ask_study_question(your_question)\n",
    "else:\n",
    "    print(\"\\nStudy Assistant not ready. Please ensure all previous cells ran successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70297508",
   "metadata": {},
   "source": [
    "## Software Engineering Study Assistant Summary\n",
    "\n",
    "This notebook successfully implements a comprehensive study assistant for software engineering students with:\n",
    "\n",
    "1. **PyMuPDF** - Extracts text from lecture notes, textbooks, and previous year papers\n",
    "2. **RecursiveCharacterTextSplitter** - Creates intelligent chunks for better knowledge retrieval\n",
    "3. **Sentence Transformers** (all-MiniLM-L6-v2) - Semantic understanding of technical concepts\n",
    "4. **ChromaDB** - Fast search across your entire study material collection\n",
    "5. **LangChain Retriever** - Finds most relevant content for your questions\n",
    "6. **Gemini Pro** - Provides detailed explanations with proper context and references\n",
    "\n",
    "**Perfect for:**\n",
    "- Understanding complex software engineering concepts\n",
    "- Solving previous year exam questions step-by-step\n",
    "- Getting quick explanations with proper source references\n",
    "- Preparing for exams with comprehensive study assistance\n",
    "- Clarifying doubts from multiple lecture sources\n",
    "\n",
    "**To get started:**\n",
    "1. Get your free Gemini API key from [Google AI Studio](https://makersuite.google.com/app/apikey)\n",
    "2. Replace `your-gemini-api-key-here` with your actual API key\n",
    "3. Add your lecture notes PDFs to the `pdf_paths` list in the PDF extraction cell\n",
    "4. Run all cells to build your knowledge base\n",
    "5. Start asking questions about your course materials!\n",
    "\n",
    "**Pro Tips:**\n",
    "- Add all your course PDFs for comprehensive coverage\n",
    "- Ask specific questions for better answers\n",
    "- Use the source references to dive deeper into topics\n",
    "- Perfect for exam preparation and assignment help"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
